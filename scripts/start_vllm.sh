#!/bin/bash

# VLLM OpenAI νΈν™ μ„λ²„ μ‹¤ν–‰ μ¤ν¬λ¦½νΈ
# νμΈνλ‹λ Qwen λ¨λΈμ„ μ‚¬μ©ν• LLM μ„λ²„λ¥Ό μ‹μ‘ν•©λ‹λ‹¤.

# μ¤ν¬λ¦½νΈ λ””λ ‰ν† λ¦¬λ¥Ό κΈ°μ¤€μΌλ΅ ν”„λ΅μ νΈ λ£¨νΈ μ„¤μ •
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"

# κΈ°λ³Έ μ„¤μ •κ°’
HOST="0.0.0.0"
PORT=8000
BASE_MODEL="Qwen/Qwen2.5-14B-Instruct"
ADAPTER_PATH="$PROJECT_ROOT/qwen25-14b"  # ν”„λ΅μ νΈ λ£¨νΈ κΈ°μ¤€ μƒλ€ κ²½λ΅
LOG_DIR="$PROJECT_ROOT/logs"
LOG_FILE="$LOG_DIR/vllm_server.log"
DTYPE="half"  # λλ” "bfloat16", "float16"
MAX_MODEL_LEN=4096
MAX_NUM_SEQS=256
GPU_MEM_UTIL=0.9

# λ΅κ·Έ λ””λ ‰ν† λ¦¬ μƒμ„±
mkdir -p "$LOG_DIR"

# λ””λ²„κΉ… μ •λ³΄ μ¶λ ¥
echo "================ ν™κ²½ μ •λ³΄ ================"
echo "μ¤ν¬λ¦½νΈ λ””λ ‰ν† λ¦¬: $SCRIPT_DIR"
echo "ν”„λ΅μ νΈ λ£¨νΈ: $PROJECT_ROOT"
echo "λ¨λΈ νμΈνλ‹ κ²½λ΅: $ADAPTER_PATH"
echo "==========================================="

# κ°€μƒν™κ²½ ν™μ„±ν™”
if [ -f "${PROJECT_ROOT}/venv/bin/activate" ]; then
    source "${PROJECT_ROOT}/venv/bin/activate"
    echo "β… κ°€μƒν™κ²½ ν™μ„±ν™”λ¨"
elif [ -f "${PROJECT_ROOT}/.venv/bin/activate" ]; then
    source "${PROJECT_ROOT}/.venv/bin/activate"
    echo "β… κ°€μƒν™κ²½(.venv) ν™μ„±ν™”λ¨"
else
    echo "β οΈ κ°€μƒν™κ²½μ„ μ°Ύμ„ μ μ—†μµλ‹λ‹¤. μ‹μ¤ν… Pythonμ„ μ‚¬μ©ν•©λ‹λ‹¤."
fi

# λ¨λΈ λ””λ ‰ν† λ¦¬ ν™•μΈ (νμΈνλ‹λ λ¨λΈμΈ κ²½μ°)
if [[ "$ADAPTER_PATH" != *"/"* ]]; then
    echo "β οΈ νμΈνλ‹ μ–΄λ‘ν„° κ²½λ΅κ°€ μ§€μ •λμ§€ μ•μ•μµλ‹λ‹¤. κΈ°λ³Έ λ¨λΈλ§ μ‚¬μ©ν•©λ‹λ‹¤."
    USE_PEFT=false
elif [ ! -d "$ADAPTER_PATH" ]; then
    echo "β οΈ νμΈνλ‹ μ–΄λ‘ν„° λ””λ ‰ν† λ¦¬λ¥Ό μ°Ύμ„ μ μ—†μµλ‹λ‹¤: $ADAPTER_PATH"
    echo "β οΈ κΈ°λ³Έ λ¨λΈλ§ μ‚¬μ©ν•©λ‹λ‹¤."
    USE_PEFT=false
else
    echo "β… νμΈνλ‹ μ–΄λ‘ν„° κ²½λ΅ ν™•μΈλ¨: $ADAPTER_PATH"
    USE_PEFT=true
fi

# ν™κ²½ λ³€μ μ„¤μ •
export PYTORCH_CUDA_ALLOC_CONF="max_split_size_mb:512,expandable_segments:True"

# λ„μ›€λ§ μ¶λ ¥
function show_help {
    echo "μ‚¬μ©λ²•: $0 [μµμ…]"
    echo ""
    echo "μµμ…:"
    echo "  -h, --help               λ„μ›€λ§ ν‘μ‹"
    echo "  -m, --model MODEL        κΈ°λ³Έ λ¨λΈ κ²½λ΅ (κΈ°λ³Έκ°’: $BASE_MODEL)"
    echo "  -a, --adapter PATH       νμΈνλ‹ μ–΄λ‘ν„° κ²½λ΅ (κΈ°λ³Έκ°’: $ADAPTER_PATH)"
    echo "  --host HOST              μ„λ²„ νΈμ¤νΈ (κΈ°λ³Έκ°’: $HOST)"
    echo "  -p, --port PORT          μ„λ²„ ν¬νΈ (κΈ°λ³Έκ°’: $PORT)"
    echo "  --dtype TYPE             λ°μ΄ν„° νƒ€μ… [half, float16, bfloat16] (κΈ°λ³Έκ°’: $DTYPE)"
    echo "  --max-model-len LEN      μµλ€ λ¨λΈ κΈΈμ΄ (κΈ°λ³Έκ°’: $MAX_MODEL_LEN)"
    echo "  --max-num-seqs NUM       μµλ€ λ™μ‹ μ”μ²­ μ (κΈ°λ³Έκ°’: $MAX_NUM_SEQS)"
    echo "  --gpu-mem-util FLOAT     GPU λ©”λ¨λ¦¬ μ‚¬μ©λ¥  0.0-1.0 (κΈ°λ³Έκ°’: $GPU_MEM_UTIL)"
    echo ""
    exit 0
}

# λ…λ Ήμ¤„ μΈμ νμ‹±
while (( "$#" )); do
    case "$1" in
        -h|--help)
            show_help
            ;;
        -m|--model)
            if [ -n "$2" ] && [ ${2:0:1} != "-" ]; then
                BASE_MODEL=$2
                shift 2
            else
                echo "μ¤λ¥: --model μΈμ λ‹¤μμ— κ°’μ΄ ν•„μ”ν•©λ‹λ‹¤."
                exit 1
            fi
            ;;
        -a|--adapter)
            if [ -n "$2" ] && [ ${2:0:1} != "-" ]; then
                ADAPTER_PATH=$2
                # λ¨λΈ λ””λ ‰ν† λ¦¬ λ‹¤μ‹ ν™•μΈ
                if [ ! -d "$ADAPTER_PATH" ]; then
                    echo "β οΈ νμΈνλ‹ μ–΄λ‘ν„° λ””λ ‰ν† λ¦¬λ¥Ό μ°Ύμ„ μ μ—†μµλ‹λ‹¤: $ADAPTER_PATH"
                    USE_PEFT=false
                else
                    USE_PEFT=true
                fi
                shift 2
            else
                echo "μ¤λ¥: --adapter μΈμ λ‹¤μμ— κ°’μ΄ ν•„μ”ν•©λ‹λ‹¤."
                exit 1
            fi
            ;;
        --host)
            if [ -n "$2" ] && [ ${2:0:1} != "-" ]; then
                HOST=$2
                shift 2
            else
                echo "μ¤λ¥: --host μΈμ λ‹¤μμ— κ°’μ΄ ν•„μ”ν•©λ‹λ‹¤."
                exit 1
            fi
            ;;
        -p|--port)
            if [ -n "$2" ] && [ ${2:0:1} != "-" ]; then
                PORT=$2
                shift 2
            else
                echo "μ¤λ¥: --port μΈμ λ‹¤μμ— κ°’μ΄ ν•„μ”ν•©λ‹λ‹¤."
                exit 1
            fi
            ;;
        --dtype)
            if [ -n "$2" ] && [ ${2:0:1} != "-" ]; then
                DTYPE=$2
                shift 2
            else
                echo "μ¤λ¥: --dtype μΈμ λ‹¤μμ— κ°’μ΄ ν•„μ”ν•©λ‹λ‹¤."
                exit 1
            fi
            ;;
        --max-model-len)
            if [ -n "$2" ] && [ ${2:0:1} != "-" ]; then
                MAX_MODEL_LEN=$2
                shift 2
            else
                echo "μ¤λ¥: --max-model-len μΈμ λ‹¤μμ— κ°’μ΄ ν•„μ”ν•©λ‹λ‹¤."
                exit 1
            fi
            ;;
        --max-num-seqs)
            if [ -n "$2" ] && [ ${2:0:1} != "-" ]; then
                MAX_NUM_SEQS=$2
                shift 2
            else
                echo "μ¤λ¥: --max-num-seqs μΈμ λ‹¤μμ— κ°’μ΄ ν•„μ”ν•©λ‹λ‹¤."
                exit 1
            fi
            ;;
        --gpu-mem-util)
            if [ -n "$2" ] && [ ${2:0:1} != "-" ]; then
                GPU_MEM_UTIL=$2
                shift 2
            else
                echo "μ¤λ¥: --gpu-mem-util μΈμ λ‹¤μμ— κ°’μ΄ ν•„μ”ν•©λ‹λ‹¤."
                exit 1
            fi
            ;;
        *)
            shift
            ;;
    esac
done

echo "======================= VLLM μ„λ²„ μ‹μ‘ ======================="
echo "π“‚ κΈ°λ³Έ λ¨λΈ: $BASE_MODEL"
if [ "$USE_PEFT" = true ]; then
    echo "π“‚ νμΈνλ‹ μ–΄λ‘ν„°: $ADAPTER_PATH"
else
    echo "β οΈ νμΈνλ‹ μ–΄λ‘ν„° μ—†μ - κΈ°λ³Έ λ¨λΈλ§ μ‚¬μ©ν•©λ‹λ‹¤"
fi
echo "π μ„λ²„ μ£Όμ†: http://$HOST:$PORT"
echo "π“ λ°μ΄ν„° νƒ€μ…: $DTYPE"
echo "π“ λ΅κ·Έ νμΌ: $LOG_FILE"
echo "=============================================================="

echo "π€ μ„λ²„λ¥Ό μ‹μ‘ν•©λ‹λ‹¤..."

# ν„μ¬ λ””λ ‰ν† λ¦¬λ¥Ό ν”„λ΅μ νΈ λ£¨νΈλ΅ λ³€κ²½
cd "$PROJECT_ROOT"
echo "ν„μ¬ λ””λ ‰ν† λ¦¬: $(pwd)"

# VLLM OpenAI νΈν™ μ„λ²„ μ§μ ‘ μ‹¤ν–‰
if [ "$USE_PEFT" = true ]; then
    # νμΈνλ‹ λ¨λΈ μ‚¬μ©
    python -m vllm.entrypoints.openai.api_server \
        --model "$BASE_MODEL" \
        --peft-model-path "$ADAPTER_PATH" \
        --host "$HOST" \
        --port "$PORT" \
        --dtype "$DTYPE" \
        --max-model-len "$MAX_MODEL_LEN" \
        --trust-remote-code \
        --max-num-seqs "$MAX_NUM_SEQS" \
        --gpu-memory-utilization "$GPU_MEM_UTIL" \
        2>&1 | tee -a "$LOG_FILE"
else
    # κΈ°λ³Έ λ¨λΈλ§ μ‚¬μ©
    python -m vllm.entrypoints.openai.api_server \
        --model "$BASE_MODEL" \
        --host "$HOST" \
        --port "$PORT" \
        --dtype "$DTYPE" \
        --max-model-len "$MAX_MODEL_LEN" \
        --trust-remote-code \
        --max-num-seqs "$MAX_NUM_SEQS" \
        --gpu-memory-utilization "$GPU_MEM_UTIL" \
        2>&1 | tee -a "$LOG_FILE"
fi

# μ„λ²„ μΆ…λ£μ‹ λ©”μ‹μ§€
echo "β… VLLM μ„λ²„κ°€ μΆ…λ£λμ—μµλ‹λ‹¤."
